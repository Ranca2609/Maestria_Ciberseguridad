# Gu√≠a de Pruebas de Carga con Locust - QuetzalShip

## üìã Tabla de Contenidos

- [Descripci√≥n General](#descripci√≥n-general)
- [Prerrequisitos](#prerrequisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Ejecuci√≥n Local](#ejecuci√≥n-local)
- [Ejecuci√≥n en Kubernetes](#ejecuci√≥n-en-kubernetes)
- [Configuraci√≥n de Pruebas](#configuraci√≥n-de-pruebas)
- [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)
- [Escenarios de Prueba](#escenarios-de-prueba)
- [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)

---

## üìù Descripci√≥n General

Locust es una herramienta de pruebas de carga de c√≥digo abierto que simula usuarios concurrentes para evaluar el rendimiento del sistema QuetzalShip. Este proyecto incluye:

- **Archivo de pruebas**: `tests/load/locustfile.py`
- **Despliegue K8s**: `k8s/testing/locust/deployment.yaml`
- **Arquitectura**: Master-Worker para escalabilidad

### Endpoints Probados

| Endpoint | Peso | Descripci√≥n |
|----------|------|-------------|
| `GET /api/v1/orders` | 5 | Listar √≥rdenes (m√°s frecuente) |
| `POST /api/v1/orders` | 3 | Crear orden |
| `GET /health` | 2 | Health check |
| `GET /api/v1/orders/:id` | 2 | Detalles de orden |
| `GET /api/v1/orders/:id/receipt` | 1 | Obtener recibo |
| `GET /api/v1/fx/rates` | 1 | Consultar tipo de cambio |

---

## üîß Prerrequisitos

### Opci√≥n 1: Ejecuci√≥n Local

```bash
# Python 3.8 o superior
python --version

# pip actualizado
pip --version
```

### Opci√≥n 2: Ejecuci√≥n en Kubernetes

```bash
# Cluster de Kubernetes activo
kubectl cluster-info

# Namespace quetzalship creado
kubectl get namespace quetzalship
```

---

## üì¶ Instalaci√≥n

### Instalaci√≥n Local de Locust

```bash
# Crear entorno virtual (recomendado)
python -m venv venv

# Activar entorno virtual
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate

# Instalar Locust
pip install locust

# Verificar instalaci√≥n
locust --version
```

### Instalaci√≥n de Dependencias Adicionales

```bash
# Si necesitas generar reportes
pip install locust-plugins
```

---

## üöÄ Ejecuci√≥n Local

### 1. Navegaci√≥n al Directorio

```bash
cd tests/load
```

### 2. Ejecuci√≥n B√°sica con Interfaz Web

```bash
# Apuntar al gateway local
locust -f locustfile.py --host http://localhost:3000
```

Luego abre tu navegador en: **http://localhost:8089**

#### Configuraci√≥n en la UI Web:

- **Number of users**: Usuarios concurrentes (ej: 100)
- **Spawn rate**: Usuarios por segundo (ej: 10)
- **Host**: Ya configurado en comando

### 3. Ejecuci√≥n sin Interfaz (Headless)

```bash
# Prueba r√°pida: 50 usuarios, 10 spawn rate, 60 segundos
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 50 \
  --spawn-rate 10 \
  --run-time 60s

# Prueba de estr√©s: 200 usuarios, duraci√≥n 5 minutos
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 200 \
  --spawn-rate 20 \
  --run-time 5m
```

### 4. Generar Reportes

```bash
# Con reporte HTML
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 100 \
  --spawn-rate 10 \
  --run-time 2m \
  --html report.html

# Con reporte CSV
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 100 \
  --spawn-rate 10 \
  --run-time 2m \
  --csv results
```

### 5. Ejecuci√≥n contra Entornos Diferentes

```bash
# Desarrollo
locust -f locustfile.py --host http://localhost:3000

# Staging (Kubernetes local)
locust -f locustfile.py --host http://localhost

# Producci√≥n (con dominio)
locust -f locustfile.py --host https://quetzalship.example.com
```

---

## ‚ò∏Ô∏è Ejecuci√≥n en Kubernetes

### 1. Desplegar Locust en Cluster

```bash
# Aplicar configuraci√≥n
kubectl apply -f k8s/testing/locust/deployment.yaml

# Verificar despliegue
kubectl get pods -n quetzalship -l app=locust

# Verificar servicios
kubectl get svc -n quetzalship -l app=locust
```

### 2. Acceder a la Interfaz Web

#### Opci√≥n A: Port Forward

```bash
# Exponer UI de Locust localmente
kubectl port-forward -n quetzalship svc/locust-master 8089:8089

# Abrir navegador en: http://localhost:8089
```

#### Opci√≥n B: Ingress (si est√° configurado)

```bash
# Obtener host del ingress
kubectl get ingress -n quetzalship locust-ingress

# Agregar a /etc/hosts (Linux/Mac) o C:\Windows\System32\drivers\etc\hosts (Windows)
# <EXTERNAL-IP> locust.quetzalship.local

# Acceder en navegador: http://locust.quetzalship.local
```

### 3. Escalar Workers

```bash
# Escalar a 5 workers para m√°s carga
kubectl scale deployment locust-worker -n quetzalship --replicas=5

# Verificar escalado
kubectl get pods -n quetzalship -l role=worker
```

### 4. Ver Logs

```bash
# Logs del master
kubectl logs -n quetzalship -l role=master -f

# Logs de workers
kubectl logs -n quetzalship -l role=worker -f

# Logs de un worker espec√≠fico
kubectl logs -n quetzalship <worker-pod-name> -f
```

### 5. Limpiar Recursos

```bash
# Eliminar despliegue de Locust
kubectl delete -f k8s/testing/locust/deployment.yaml

# O eliminar recursos individuales
kubectl delete deployment locust-master locust-worker -n quetzalship
kubectl delete svc locust-master -n quetzalship
kubectl delete configmap locust-config -n quetzalship
```

---

## ‚öôÔ∏è Configuraci√≥n de Pruebas

### Modificar el Locustfile

El archivo `tests/load/locustfile.py` define el comportamiento de los usuarios simulados:

```python
# Ajustar tiempo de espera entre tareas
wait_time = between(1, 3)  # 1-3 segundos

# Modificar pesos de tareas
@task(5)  # Peso 5 - m√°s frecuente
def list_orders(self):
    ...

@task(1)  # Peso 1 - menos frecuente
def get_fx_rate(self):
    ...
```

### Escenarios Personalizados

#### Prueba de Carga Sostenida

```bash
# 100 usuarios durante 30 minutos
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 100 \
  --spawn-rate 5 \
  --run-time 30m
```

#### Prueba de Pico (Spike Test)

```bash
# Incremento r√°pido: 500 usuarios en 10 segundos
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 500 \
  --spawn-rate 50 \
  --run-time 2m
```

#### Prueba de Estr√©s

```bash
# Incrementar gradualmente hasta fallo
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 1000 \
  --spawn-rate 10 \
  --run-time 10m
```

#### Prueba de Resistencia (Soak Test)

```bash
# Carga moderada durante tiempo prolongado
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 50 \
  --spawn-rate 5 \
  --run-time 2h
```

---

## üìä Interpretaci√≥n de Resultados

### M√©tricas Clave

La interfaz de Locust muestra:

| M√©trica | Descripci√≥n | Valores Ideales |
|---------|-------------|-----------------|
| **RPS** | Requests per Second | > 100 RPS |
| **Response Time (avg)** | Tiempo promedio | < 200ms |
| **Response Time (95%)** | Percentil 95 | < 500ms |
| **Failure Rate** | Porcentaje de fallos | < 1% |
| **Current Users** | Usuarios activos | Seg√∫n configuraci√≥n |

### An√°lisis de Resultados

#### ‚úÖ Resultados Buenos

```
Type        Name                    # reqs    # fails   Avg    Min    Max  Median  req/s
------------------------------------------------------------------------------------------
GET         /api/v1/orders           5000      0       120     50    450    100    167
POST        /api/v1/orders           3000      0       180     80    600    150    100
GET         /health                  2000      0        45     20    150     40     67

Total                               10000      0       125     20    600    100    334
```

- Tasa de fallo: 0%
- Tiempos de respuesta estables
- RPS alto y sostenido

#### ‚ö†Ô∏è Resultados con Problemas

```
Type        Name                    # reqs    # fails   Avg    Min    Max  Median  req/s
------------------------------------------------------------------------------------------
POST        /api/v1/orders           1500     450     2500    100   8000   2000     50
GET         /api/v1/orders           3000     100     1200     50   5000    900    100

Total                                4500     550     1650     50   8000   1200    150
```

- Alta tasa de fallo (12%)
- Tiempos de respuesta elevados
- Possible sobrecarga del sistema

### Exportar Estad√≠sticas

```bash
# Durante ejecuci√≥n headless, se generan archivos CSV
# results_stats.csv - Estad√≠sticas generales
# results_stats_history.csv - Hist√≥rico
# results_failures.csv - Fallos registrados
```

---

## üéØ Escenarios de Prueba

### Escenario 1: Validaci√≥n B√°sica

**Objetivo**: Verificar que el sistema funciona correctamente bajo carga m√≠nima.

```bash
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 10 \
  --spawn-rate 2 \
  --run-time 1m
```

**Criterios de √âxito**:
- 0% de fallos
- Tiempo de respuesta < 200ms

### Escenario 2: Carga Normal

**Objetivo**: Simular tr√°fico t√≠pico de producci√≥n.

```bash
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 100 \
  --spawn-rate 10 \
  --run-time 10m
```

**Criterios de √âxito**:
- < 1% fallos
- Avg response < 300ms
- P95 < 500ms

### Escenario 3: Carga Pico

**Objetivo**: Evaluar comportamiento durante picos de tr√°fico.

```bash
locust -f locustfile.py \
  --host http://localhost:3000 \
  --headless \
  --users 300 \
  --spawn-rate 30 \
  --run-time 5m
```

**Criterios de √âxito**:
- < 5% fallos
- Avg response < 500ms
- Sistema no colapsa

### Escenario 4: Prueba de L√≠mites

**Objetivo**: Encontrar el punto de quiebre del sistema.

```bash
# Incrementar usuarios hasta que fallen las pruebas
for users in 100 200 500 1000 2000; do
  echo "Testing with $users users..."
  locust -f locustfile.py \
    --host http://localhost:3000 \
    --headless \
    --users $users \
    --spawn-rate 50 \
    --run-time 2m \
    --html report_${users}_users.html
  sleep 10
done
```

---

## üîç Monitoreo Durante Pruebas

### Monitoreo del Gateway (Kubernetes)

```bash
# CPU y Memoria del gateway
kubectl top pod -n quetzalship -l app=gateway

# Logs en tiempo real
kubectl logs -n quetzalship -l app=gateway -f --tail=100
```

### Monitoreo de Servicios

```bash
# Todos los pods
kubectl top pod -n quetzalship

# Servicios espec√≠ficos
kubectl top pod -n quetzalship -l app=orders
kubectl top pod -n quetzalship -l app=pricing
```

### Grafana (si est√° desplegado)

```bash
# Port-forward a Grafana
kubectl port-forward -n quetzalship svc/grafana 3001:80

# Dashboard URL: http://localhost:3001
# Usuario: admin / admin
```

M√©tricas a observar:
- Request rate
- Response time percentiles
- Error rate
- CPU/Memory usage
- Database connections

---

## üêõ Soluci√≥n de Problemas

### Error: "Connection refused"

```bash
# Verificar que el servicio est√© corriendo
curl http://localhost:3000/health

# Si est√° en K8s
kubectl get svc -n quetzalship gateway-service
```

### Error: "Too many open files"

```bash
# Aumentar l√≠mite de archivos (Linux/Mac)
ulimit -n 10000

# Verificar l√≠mite actual
ulimit -n
```

### Alto porcentaje de fallos

1. **Revisar logs del servidor**:
   ```bash
   kubectl logs -n quetzalship -l app=gateway --tail=100
   ```

2. **Reducir carga**:
   ```bash
   # Menos usuarios o spawn rate m√°s lento
   --users 50 --spawn-rate 5
   ```

3. **Verificar recursos**:
   ```bash
   kubectl top pod -n quetzalship
   ```

### Workers no conectan al Master (K8s)

```bash
# Verificar servicio del master
kubectl get svc -n quetzalship locust-master

# Revisar logs de workers
kubectl logs -n quetzalship -l role=worker

# Verificar conectividad
kubectl exec -n quetzalship -it <worker-pod> -- ping locust-master
```

### Locust UI no carga

```bash
# Verificar port-forward
kubectl port-forward -n quetzalship svc/locust-master 8089:8089

# Verificar pod del master
kubectl get pod -n quetzalship -l role=master

# Ver logs
kubectl logs -n quetzalship -l role=master
```

---

## üìà Mejores Pr√°cticas

### 1. Configuraci√≥n Gradual

- Empezar con pocos usuarios (10-20)
- Incrementar gradualmente
- Observar m√©tricas en cada paso

### 2. Tiempos de Espera Realistas

```python
# Simular comportamiento humano
wait_time = between(1, 5)  # No usar 0
```

### 3. Distribuci√≥n de Carga

```python
# Usar pesos apropiados seg√∫n tr√°fico real
@task(10)  # Operaci√≥n muy frecuente
@task(1)   # Operaci√≥n rara
```

### 4. Cleanup de Datos

- Las pruebas crean √≥rdenes en la BD
- Limpiar datos de prueba peri√≥dicamente
- Usar BD de prueba separada si es posible

### 5. Monitoreo Completo

- Observar m√©tricas del servidor simult√°neamente
- Usar Grafana/Kibana durante las pruebas
- Revisar logs para errores ocultos

---

## üîó Recursos Adicionales

- [Documentaci√≥n Oficial de Locust](https://docs.locust.io/)
- [Locust on GitHub](https://github.com/locustio/locust)
- [Best Practices for Load Testing](https://docs.locust.io/en/stable/running-in-kubernetes.html)

---

## üìù Checklist de Pruebas

Antes de considerar las pruebas completas:

- [ ] Validaci√≥n b√°sica (10 usuarios) - 0% fallos
- [ ] Carga normal (100 usuarios) - < 1% fallos
- [ ] Carga pico (300 usuarios) - < 5% fallos
- [ ] Prueba de resistencia (2 horas) - sistema estable
- [ ] Reportes generados y revisados
- [ ] M√©tricas de Grafana revisadas
- [ ] Logs sin errores cr√≠ticos
- [ ] Documentaci√≥n de resultados

---

## üìû Contacto y Soporte

Para problemas o preguntas sobre las pruebas de carga:
- Revisar logs del sistema
- Consultar documentaci√≥n en `docs/`
- Verificar configuraci√≥n de Kubernetes

**√öltima actualizaci√≥n**: Diciembre 2025
